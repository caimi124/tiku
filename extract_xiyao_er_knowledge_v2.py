#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¥¿è¯è¯äºŒçŸ¥è¯†ç‚¹æå–è„šæœ¬ V2 - å¢å¼ºç‰ˆ
ä» layout.json ä¸­æå–è¯ç†å­¦çŸ¥è¯†ç‚¹ï¼ŒåŒ…æ‹¬å›¾ç‰‡ä¸­çš„è¡¨æ ¼ä¿¡æ¯

å¢å¼ºåŠŸèƒ½ï¼š
1. è§£ælayout.jsonä¸­çš„è¡¨æ ¼HTMLæ•°æ®
2. æå–å›¾ç‰‡è·¯å¾„ï¼Œæ”¯æŒåç»­OCRå¤„ç†
3. æ›´å®Œæ•´åœ°æå–è¯ç‰©ä½œç”¨ç‰¹ç‚¹ã€å…¸å‹ä¸è‰¯ååº”ã€è¯ç‰©ç›¸äº’ä½œç”¨

ä½¿ç”¨æ–¹æ³•ï¼š
python extract_xiyao_er_knowledge_v2.py

è¾“å…¥ï¼šshuju/layout.json, shuju/images/
è¾“å‡ºï¼šshuju/è¥¿è¯è¯äºŒ_çŸ¥è¯†ç‚¹_å®Œæ•´ç‰ˆ.json
"""

import json
import re
import os
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field, asdict
from collections import defaultdict
from pathlib import Path
from bs4 import BeautifulSoup
import html


@dataclass
class DrugCharacteristics:
    """è¯ç‰©ä½œç”¨ç‰¹ç‚¹"""
    mechanism: List[str] = field(default_factory=list)  # ä½œç”¨æœºåˆ¶
    selectivity: str = ""  # é€‰æ‹©æ€§
    indications: List[str] = field(default_factory=list)  # é€‚åº”è¯
    pharmacokinetics: Dict[str, str] = field(default_factory=dict)  # è¯åŠ¨å­¦ç‰¹ç‚¹
    special_features: List[str] = field(default_factory=list)  # ç‰¹æ®Šä½œç”¨ç‰¹ç‚¹


@dataclass
class AdverseReactions:
    """ä¸è‰¯ååº”ï¼ˆæŒ‰ä¸¥é‡ç¨‹åº¦å’Œç±»å‹åˆ†çº§ï¼‰"""
    severe: List[str] = field(default_factory=list)      # ä¸¥é‡ä¸è‰¯ååº”
    moderate: List[str] = field(default_factory=list)    # ä¸­åº¦ä¸è‰¯ååº”
    mild: List[str] = field(default_factory=list)        # è½»åº¦ä¸è‰¯ååº”
    common: List[str] = field(default_factory=list)      # å¸¸è§ä¸è‰¯ååº”
    typical: List[str] = field(default_factory=list)     # å…¸å‹ä¸è‰¯ååº”


@dataclass
class DrugInteractions:
    """è¯ç‰©ç›¸äº’ä½œç”¨"""
    synergistic: List[str] = field(default_factory=list)  # ååŒä½œç”¨
    antagonistic: List[str] = field(default_factory=list)  # æ‹®æŠ—ä½œç”¨
    contraindicated: List[str] = field(default_factory=list)  # ç¦å¿Œåˆç”¨
    caution: List[str] = field(default_factory=list)  # æ…é‡åˆç”¨
    general: List[str] = field(default_factory=list)  # ä¸€èˆ¬ç›¸äº’ä½œç”¨


@dataclass
class DrugInfo:
    """è¯ç‰©å®Œæ•´ä¿¡æ¯"""
    name: str
    category: str = ""  # è¯ç‰©åˆ†ç±»
    subcategory: str = ""  # è¯ç‰©äºšç±»
    characteristics: DrugCharacteristics = field(default_factory=DrugCharacteristics)
    adverse_reactions: AdverseReactions = field(default_factory=AdverseReactions)
    interactions: DrugInteractions = field(default_factory=DrugInteractions)
    contraindications: List[str] = field(default_factory=list)  # ç¦å¿Œè¯
    precautions: List[str] = field(default_factory=list)  # æ³¨æ„äº‹é¡¹
    dosage: Dict[str, str] = field(default_factory=dict)  # ç”¨æ³•ç”¨é‡
    clinical_use: List[str] = field(default_factory=list)  # ä¸´åºŠåº”ç”¨
    special_populations: Dict[str, str] = field(default_factory=dict)  # ç‰¹æ®Šäººç¾¤ç”¨è¯
    exam_points: List[str] = field(default_factory=list)  # è€ƒç‚¹æ ‡è®°
    related_images: List[str] = field(default_factory=list)  # ç›¸å…³å›¾ç‰‡è·¯å¾„


@dataclass
class TableData:
    """è¡¨æ ¼æ•°æ®"""
    title: str = ""
    headers: List[str] = field(default_factory=list)
    rows: List[Dict[str, str]] = field(default_factory=list)
    source_image: str = ""
    page_idx: int = 0


@dataclass
class ExamPoint:
    """è€ƒç‚¹ä¿¡æ¯"""
    name: str
    chapter: str
    section: str
    exam_years: List[str] = field(default_factory=list)
    content: str = ""
    related_drugs: List[str] = field(default_factory=list)
    tables: List[TableData] = field(default_factory=list)
    images: List[str] = field(default_factory=list)


class EnhancedKnowledgeExtractor:
    """å¢å¼ºç‰ˆçŸ¥è¯†ç‚¹æå–å™¨"""
    
    # ç« èŠ‚æ ‡é¢˜æ­£åˆ™
    CHAPTER_PATTERN = re.compile(r'^ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)ç« \s*(.+?)(?:\s*//\s*\d+)?$')
    SECTION_PATTERN = re.compile(r'^ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)èŠ‚\s*(.+?)(?:\s*\.{2,}|\s+)?\d*$')
    EXAM_POINT_PATTERN = re.compile(r'^è€ƒç‚¹\s*(\d+)\s*(.+)$')
    
    # ä¸­æ–‡æ•°å­—æ˜ å°„
    CN_NUM_MAP = {
        'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5,
        'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'å': 10,
        'åä¸€': 11, 'åäºŒ': 12, 'åä¸‰': 13, 'åå››': 14, 'åäº”': 15
    }
    
    # è¯ç‰©åç§°è¯†åˆ« - æ‰©å±•åˆ—è¡¨
    KNOWN_DRUGS = [
        # é•‡é™å‚¬çœ è¯
        'åœ°è¥¿æ³®', 'è‰¾å¸å”‘ä»‘', 'ä¸‰å”‘ä»‘', 'å’ªè¾¾å”‘ä»‘', 'åŠ³æ‹‰è¥¿æ³®', 'æ°¯ç¡è¥¿æ³®',
        'å”‘å¡å¦', 'ä½åŒ¹å…‹éš†', 'æ‰æ¥æ™®éš†', 'é›·ç¾æ›¿èƒº',
        'è‹¯å·´æ¯”å¦¥', 'å¸å¯å·´æ¯”å¦¥', 'æ°´åˆæ°¯é†›',
        'å·´æ°¯èŠ¬', 'æ›¿æ‰å°¼å®š', 'ä¹™å“Œç«‹æ¾',
        # æŠ—ç™«ç—«è¯
        'å¡é©¬è¥¿å¹³', 'å¥¥å¡è¥¿å¹³', 'è‹¯å¦¥è‹±é’ ', 'ä¸™æˆŠé…¸é’ ', 'æ‹‰è«ä¸‰å—ª',
        'å·¦ä¹™æ‹‰è¥¿å¦', 'æ‰˜å¡é…¯', 'åŠ å·´å–·ä¸', 'æ™®ç‘å·´æ—', 'ä¹™ç¥èƒº',
        # æŠ—æŠ‘éƒè¯
        'æ°Ÿè¥¿æ±€', 'å¸•ç½—è¥¿æ±€', 'èˆæ›²æ—', 'è¥¿é…æ™®å…°', 'è‰¾å¸è¥¿é…æ™®å…°',
        'æ–‡æ‹‰æ³•è¾›', 'åº¦æ´›è¥¿æ±€', 'ç±³æ°®å¹³', 'é˜¿ç±³æ›¿æ—', 'ä¸™ç±³å—ª',
        # é•‡ç—›è¯
        'å—å•¡', 'èŠ¬å¤ªå°¼', 'èˆ’èŠ¬å¤ªå°¼', 'ç‘èŠ¬å¤ªå°¼', 'ç¾Ÿè€ƒé…®', 'æ°¢å—å•¡é…®',
        'å“Œæ›¿å•¶', 'æ›²é©¬å¤š', 'å¯å¾…å› ', 'ä¸ä¸™è¯ºå•¡', 'çº³æ´›é…®', 'çº³æ›²é…®',
        # æŠ—å¸•é‡‘æ£®è¯
        'å·¦æ—‹å¤šå·´', 'å¡æ¯”å¤šå·´', 'è‹„ä¸è‚¼', 'æ™®æ‹‰å…‹ç´¢', 'ç½—åŒ¹å°¼ç½—',
        'å¸æ¥å‰å…°', 'é›·æ²™å‰å…°', 'æ©ä»–å¡æœ‹', 'è‹¯æµ·ç´¢', 'é‡‘åˆšçƒ·èƒº',
        # æŠ—ç²¾ç¥ç—…è¯
        'æ°¯ä¸™å—ª', 'æ°Ÿå“Œå•¶é†‡', 'åˆ©åŸ¹é…®', 'å¥¥æ°®å¹³', 'å–¹ç¡«å¹³',
        'é˜¿ç«‹å“Œå”‘', 'é½æ‹‰è¥¿é…®', 'æ°¯æ°®å¹³', 'ç¢³é…¸é”‚',
        # NSAIDs
        'é˜¿å¸åŒ¹æ—', 'å¸ƒæ´›èŠ¬', 'è˜æ™®ç”Ÿ', 'å²å“šç¾è¾›', 'åŒæ°¯èŠ¬é…¸',
        'å¡æ¥æ˜”å¸ƒ', 'ä¾æ‰˜è€ƒæ˜”', 'ç¾æ´›æ˜”åº·', 'å¯¹ä¹™é…°æ°¨åŸºé…š', 'å°¼ç¾èˆ’åˆ©',
        'è´è¯ºé…¯', 'èµ–æ°¨åŒ¹æ—', 'äºŒæ°Ÿå°¼æŸ³', 'èˆ’æ—é…¸', 'æ°Ÿæ¯”æ´›èŠ¬',
        'é…®æ´›èŠ¬', 'éè¯ºæ´›èŠ¬é’™', 'å¥¥æ²™æ™®ç§¦', 'ä¿æ³°æ¾', 'å®‰ä¹ƒè¿‘',
        'æ°¨åŸºæ¯”æ—', 'è˜ä¸ç¾é…®', 'å¸•ç‘æ˜”å¸ƒ', 'ä¼åœ°è€ƒæ˜”', 'è‰¾ç‘æ˜”å¸ƒ',
        # æŠ—ç—›é£è¯
        'ç§‹æ°´ä»™ç¢±', 'åˆ«å˜Œé†‡', 'éå¸ƒå¸ä»–', 'è‹¯æº´é©¬éš†', 'ä¸™ç£ºèˆ’',
        # æŠ—é£æ¹¿è¯
        'ç”²æ°¨è¶å‘¤', 'æ¥æ°Ÿç±³ç‰¹', 'æŸ³æ°®ç£ºå¡å•¶', 'ç¾Ÿæ°¯å–¹',
        # é•‡å’³è¯
        'å³ç¾æ²™èŠ¬', 'å–·æ‰˜ç»´æ—', 'è‹¯ä¸™å“Œæ—', 'å¯å¾…å› ',
        # ç¥›ç—°è¯
        'æ°¨æº´ç´¢', 'æº´å·±æ–°', 'ä¹™é…°åŠèƒ±æ°¨é…¸', 'ç¾§ç”²å¸å¦', 'æ„ˆåˆ›ç”˜æ²¹é†š',
        # å¹³å–˜è¯
        'æ²™ä¸èƒºé†‡', 'ç‰¹å¸ƒä»–æ—', 'æ²™ç¾ç‰¹ç½—', 'ç¦è«ç‰¹ç½—', 'èŒšè¾¾ç‰¹ç½—',
        'å¼‚ä¸™æ‰˜æº´é“µ', 'å™»æ‰˜æº´é“µ', 'æ°¨èŒ¶ç¢±', 'å¤šç´¢èŒ¶ç¢±',
        'å¸ƒåœ°å¥ˆå¾·', 'æ°Ÿæ›¿å¡æ¾', 'å€æ°¯ç±³æ¾', 'å­Ÿé²å¸ç‰¹', 'æ‰é²å¸ç‰¹',
        'è‰²ç”˜é…¸é’ ', 'å¥¥é©¬ç å•æŠ—',
        # æ¶ˆåŒ–ç³»ç»Ÿ
        'å¥¥ç¾æ‹‰å”‘', 'å…°ç´¢æ‹‰å”‘', 'æ³®æ‰˜æ‹‰å”‘', 'é›·è´æ‹‰å”‘', 'è‰¾å¸å¥¥ç¾æ‹‰å”‘',
        'ä¼è¯ºæ‹‰ç”Ÿ', 'è¥¿å’ªæ›¿ä¸', 'é›·å°¼æ›¿ä¸', 'æ³•è«æ›¿ä¸',
        'ç¡«ç³–é“', 'æ¸æ©¼é…¸é“‹é’¾', 'ç±³ç´¢å‰åˆ—é†‡', 'é“ç¢³é…¸é•',
        'ç”²æ°§æ°¯æ™®èƒº', 'å¤šæ½˜ç«‹é…®', 'è«æ²™å¿…åˆ©', 'ä¼Šæ‰˜å¿…åˆ©',
        'æ˜‚ä¸¹å¸ç¼', 'æ ¼æ‹‰å¸ç¼', 'å¸•æ´›è¯ºå¸ç¼', 'é˜¿ç‘åŒ¹å¦',
        'ä¹³æœç³–', 'èšä¹™äºŒé†‡', 'æ¯”æ²™å¯å•¶', 'æ´›å“Œä¸èƒº', 'è’™è„±çŸ³æ•£',
        # æ­¢åè¯
        'ä¸œè¨èªç¢±', 'è‹¯æµ·æ‹‰æ˜', 'æ°¯ä¸™å—ª', 'ç”²æ°§æ°¯æ™®èƒº', 'æ˜‚ä¸¹å¸ç¼',
        # è‚èƒ†è¯ç‰©
        'ç‰›ç£ºç†Šå»æ°§èƒ†é…¸', 'ç†Šå»æ°§èƒ†é…¸', 'é¹…å»æ°§èƒ†é…¸', 'å»æ°¢èƒ†é…¸',
        'ä¸äºŒç£ºé…¸è…ºè‹·è›‹æ°¨é…¸', 'å¥¥å¾·æ˜”å·´ç‰¹', 'æ°¯é©¬æ˜”å·´ç‰¹', 'åˆ©å¥ˆæ˜”å·´ç‰¹',
    ]
    
    # å†…å®¹ç±»å‹å…³é”®è¯
    CONTENT_TYPE_KEYWORDS = {
        'mechanism': ['ä½œç”¨æœºåˆ¶', 'æœºåˆ¶', 'åŸç†', 'é€šè¿‡æŠ‘åˆ¶', 'é€šè¿‡æ¿€åŠ¨', 'é€šè¿‡é˜»æ–­'],
        'characteristics': ['ä½œç”¨ç‰¹ç‚¹', 'ç‰¹ç‚¹', 'ç‰¹å¾', 'é€‰æ‹©æ€§'],
        'pharmacokinetics': ['è¯åŠ¨å­¦', 'åŠè¡°æœŸ', 'ä»£è°¢', 'å¸æ”¶', 'åˆ†å¸ƒ', 'æ’æ³„', 'ç”Ÿç‰©åˆ©ç”¨åº¦'],
        'adverse_reactions': ['ä¸è‰¯ååº”', 'å‰¯ä½œç”¨', 'æ¯’æ€§', 'å…¸å‹ä¸è‰¯ååº”'],
        'contraindications': ['ç¦å¿Œ', 'ç¦ç”¨', 'ç¦å¿Œè¯', 'ç¦å¿Œç—‡'],
        'interactions': ['ç›¸äº’ä½œç”¨', 'é…ä¼', 'åˆç”¨', 'è”ç”¨', 'è¯ç‰©ç›¸äº’ä½œç”¨'],
        'indications': ['é€‚åº”è¯', 'é€‚åº”ç—‡', 'ç”¨äº', 'æ²»ç–—', 'ä¸´åºŠåº”ç”¨'],
        'dosage': ['ç”¨æ³•', 'ç”¨é‡', 'å‰‚é‡', 'ç»™è¯'],
        'precautions': ['æ³¨æ„äº‹é¡¹', 'æ…ç”¨', 'æ³¨æ„'],
    }
    
    # ä¸¥é‡ç¨‹åº¦å…³é”®è¯
    SEVERITY_KEYWORDS = {
        'severe': ['å‘¼å¸æŠ‘åˆ¶', 'è¿‡æ•æ€§ä¼‘å…‹', 'éª¨é«“æŠ‘åˆ¶', 'è‚æ¯’æ€§', 'è‚¾æ¯’æ€§', 'è‚æŸä¼¤',
                   'Stevens-Johnson', 'ä¸­æ¯’æ€§è¡¨çš®åæ­»', 'æ¶æ€§ç»¼åˆå¾', 'ä¾èµ–æ€§',
                   'å¿ƒå¾‹å¤±å¸¸', 'ç™«ç—«', 'å‡ºè¡€', 'ç©¿å­”', 'è‡´ç•¸', 'ç²’ç»†èƒç¼ºä¹',
                   'QTå»¶é•¿', '5-HTç»¼åˆå¾', 'è¶…æ•ååº”', 'èƒ°è…ºç‚', 'ç‘å¤·ç»¼åˆå¾',
                   'å¿ƒè‚Œæ¢—æ­»', 'å’ä¸­', 'æ€¥æ€§è‚¾è¡°ç«­', 'å‰¥è„±æ€§çš®ç‚'],
        'moderate': ['è‚åŠŸèƒ½', 'è‚¾åŠŸèƒ½', 'ä½è¡€å‹', 'é«˜è¡€å‹', 'å¿ƒåŠ¨è¿‡é€Ÿ',
                     'é”¥ä½“å¤–ç³»', 'ä»£è°¢ç»¼åˆå¾', 'é«˜æ³Œä¹³ç´ ', 'ä½“é‡å¢åŠ ', 'è¡€ç³–',
                     'ä¾¿ç§˜', 'è…¹æ³»', 'æ¶å¿ƒ', 'å‘•å', 'æºƒç–¡', 'ç‰™é¾ˆå¢ç”Ÿ',
                     'æ’¤è¯ç»¼åˆå¾', 'åè·³', 'è€å—æ€§', 'ä½é’ ', 'ä½é’¾', 'ä½é•',
                     'éª¨è´¨ç–æ¾', 'ç³–å°¿ç—…', 'é’å…‰çœ¼', 'æ„ŸæŸ“'],
        'mild': ['å—œç¡', 'å¤´æ™•', 'å¤´ç—›', 'å£å¹²', 'çš®ç–¹', 'ç˜™ç—’', 'ä¹åŠ›',
                 'é£Ÿæ¬²ä¸‹é™', 'è…¹èƒ€', 'è…¹éƒ¨ä¸é€‚', 'ç²¾ç¥é”™ä¹±', 'å®¿é†‰ç°è±¡'],
    }
    
    def __init__(self, layout_json_path: str, images_dir: str = None):
        self.layout_json_path = layout_json_path
        self.images_dir = images_dir or os.path.join(os.path.dirname(layout_json_path), 'images')
        self.pages = []
        self.chapters = []
        self.drugs: Dict[str, DrugInfo] = {}
        self.exam_points: List[ExamPoint] = []
        self.tables: List[TableData] = []
        self.image_references: Dict[str, Dict] = {}  # å›¾ç‰‡è·¯å¾„ -> ç›¸å…³ä¿¡æ¯
        
    def load_data(self):
        """åŠ è½½ layout.json æ•°æ®"""
        print(f"æ­£åœ¨åŠ è½½ {self.layout_json_path}...")
        with open(self.layout_json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        self.pages = data.get('pdf_info', [])
        print(f"å…±åŠ è½½ {len(self.pages)} é¡µ")
        
    def cn_to_num(self, cn: str) -> int:
        """ä¸­æ–‡æ•°å­—è½¬é˜¿æ‹‰ä¼¯æ•°å­—"""
        return self.CN_NUM_MAP.get(cn, 1)

    def parse_html_table(self, html_content: str, image_path: str = "", page_idx: int = 0) -> TableData:
        """è§£æHTMLè¡¨æ ¼å†…å®¹"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            table = soup.find('table')
            if not table:
                return None
            
            rows = table.find_all('tr')
            if not rows:
                return None
            
            # æå–è¡¨å¤´
            headers = []
            first_row = rows[0]
            for cell in first_row.find_all(['th', 'td']):
                headers.append(cell.get_text(strip=True))
            
            # æå–æ•°æ®è¡Œ
            data_rows = []
            for row in rows[1:]:
                cells = row.find_all(['th', 'td'])
                row_data = {}
                for i, cell in enumerate(cells):
                    key = headers[i] if i < len(headers) else f"col_{i}"
                    row_data[key] = cell.get_text(strip=True)
                if row_data:
                    data_rows.append(row_data)
            
            return TableData(
                headers=headers,
                rows=data_rows,
                source_image=image_path,
                page_idx=page_idx
            )
        except Exception as e:
            print(f"è§£æHTMLè¡¨æ ¼å¤±è´¥: {e}")
            return None
    
    def extract_from_page(self, page: dict) -> Dict[str, Any]:
        """ä»å•ä¸ªé¡µé¢æå–æ‰€æœ‰ä¿¡æ¯"""
        page_idx = page.get('page_idx', 0)
        result = {
            'page_idx': page_idx,
            'texts': [],
            'tables': [],
            'images': [],
            'chapter': None,
            'section': None,
        }
        
        para_blocks = page.get('para_blocks', [])
        
        for block in para_blocks:
            block_type = block.get('type', 'text')
            
            # å¤„ç†å›¾ç‰‡å—
            if block_type == 'image':
                self._process_image_block(block, result, page_idx)
            
            # å¤„ç†æ™®é€šæ–‡æœ¬å—
            elif 'lines' in block:
                for line in block['lines']:
                    for span in line.get('spans', []):
                        span_type = span.get('type', 'text')
                        content = span.get('content', '').strip()
                        
                        if span_type == 'table' and 'html' in span:
                            # è§£æè¡¨æ ¼
                            table_data = self.parse_html_table(
                                span['html'], 
                                span.get('image_path', ''),
                                page_idx
                            )
                            if table_data:
                                result['tables'].append(table_data)
                                self.tables.append(table_data)
                        elif span_type == 'image' and 'image_path' in span:
                            # è®°å½•å›¾ç‰‡å¼•ç”¨
                            img_path = span['image_path']
                            result['images'].append(img_path)
                            self.image_references[img_path] = {
                                'page_idx': page_idx,
                                'context': content
                            }
                        elif content:
                            result['texts'].append({
                                'type': block_type,
                                'content': content
                            })
            
            # å¤„ç†åˆ—è¡¨å—
            if 'blocks' in block:
                for sub_block in block['blocks']:
                    self._process_sub_block(sub_block, result, page_idx)
        
        return result
    
    def _process_image_block(self, block: dict, result: dict, page_idx: int):
        """å¤„ç†å›¾ç‰‡å—"""
        if 'blocks' in block:
            for sub_block in block['blocks']:
                sub_type = sub_block.get('type', '')
                
                if sub_type == 'image_body' and 'lines' in sub_block:
                    for line in sub_block['lines']:
                        for span in line.get('spans', []):
                            if span.get('type') == 'image' and 'image_path' in span:
                                img_path = span['image_path']
                                result['images'].append(img_path)
                                self.image_references[img_path] = {
                                    'page_idx': page_idx,
                                    'type': 'image_body'
                                }
                            elif span.get('type') == 'table' and 'html' in span:
                                table_data = self.parse_html_table(
                                    span['html'],
                                    span.get('image_path', ''),
                                    page_idx
                                )
                                if table_data:
                                    result['tables'].append(table_data)
                                    self.tables.append(table_data)
                
                elif sub_type == 'image_caption' and 'lines' in sub_block:
                    for line in sub_block['lines']:
                        for span in line.get('spans', []):
                            content = span.get('content', '').strip()
                            if content:
                                result['texts'].append({
                                    'type': 'image_caption',
                                    'content': content
                                })
    
    def _process_sub_block(self, sub_block: dict, result: dict, page_idx: int):
        """å¤„ç†å­å—"""
        if 'lines' in sub_block:
            for line in sub_block['lines']:
                for span in line.get('spans', []):
                    span_type = span.get('type', 'text')
                    content = span.get('content', '').strip()
                    
                    if span_type == 'table' and 'html' in span:
                        table_data = self.parse_html_table(
                            span['html'],
                            span.get('image_path', ''),
                            page_idx
                        )
                        if table_data:
                            result['tables'].append(table_data)
                            self.tables.append(table_data)
                    elif span_type == 'image' and 'image_path' in span:
                        img_path = span['image_path']
                        result['images'].append(img_path)
                        self.image_references[img_path] = {
                            'page_idx': page_idx,
                            'context': content
                        }
                    elif content:
                        result['texts'].append({
                            'type': sub_block.get('type', 'text'),
                            'content': content
                        })
    
    def identify_drug_name(self, text: str) -> Optional[str]:
        """è¯†åˆ«æ–‡æœ¬ä¸­çš„è¯ç‰©åç§°"""
        for drug in self.KNOWN_DRUGS:
            if drug in text:
                return drug
        return None
    
    def identify_content_type(self, text: str) -> Optional[str]:
        """è¯†åˆ«å†…å®¹ç±»å‹"""
        for content_type, keywords in self.CONTENT_TYPE_KEYWORDS.items():
            for keyword in keywords:
                if keyword in text:
                    return content_type
        return None
    
    def classify_adverse_severity(self, text: str) -> str:
        """åˆ†ç±»ä¸è‰¯ååº”ä¸¥é‡ç¨‹åº¦"""
        for severity, keywords in self.SEVERITY_KEYWORDS.items():
            for keyword in keywords:
                if keyword in text:
                    return severity
        return 'mild'
    
    def extract_drug_info_from_table(self, table: TableData) -> Dict[str, Any]:
        """ä»è¡¨æ ¼ä¸­æå–è¯ç‰©ä¿¡æ¯"""
        drug_info = {}
        
        # æ£€æŸ¥è¡¨å¤´ï¼Œç¡®å®šè¡¨æ ¼ç±»å‹
        headers_lower = [h.lower() for h in table.headers]
        
        # è¯ç‰©åˆ†ç±»è¡¨
        if 'åˆ†ç±»' in table.headers and 'ä»£è¡¨è¯å“' in table.headers:
            drug_info['type'] = 'classification'
            drug_info['data'] = []
            for row in table.rows:
                category = row.get('åˆ†ç±»', '')
                drugs = row.get('ä»£è¡¨è¯å“', '')
                drug_info['data'].append({
                    'category': category,
                    'drugs': drugs
                })
        
        # ä½œç”¨ç‰¹ç‚¹/ä¸è‰¯ååº”è¡¨
        elif 'é¡¹ç›®' in table.headers and 'å…·ä½“å†…å®¹' in table.headers:
            drug_info['type'] = 'details'
            drug_info['data'] = {}
            for row in table.rows:
                item = row.get('é¡¹ç›®', '')
                content = row.get('å…·ä½“å†…å®¹', '')
                
                if 'ä½œç”¨æœºåˆ¶' in item:
                    drug_info['data']['mechanism'] = content
                elif 'ä½œç”¨ç‰¹ç‚¹' in item:
                    drug_info['data']['characteristics'] = content
                elif 'ä¸è‰¯ååº”' in item or 'å…¸å‹ä¸è‰¯ååº”' in item:
                    drug_info['data']['adverse_reactions'] = content
                elif 'ç¦å¿Œ' in item:
                    drug_info['data']['contraindications'] = content
                elif 'ç›¸äº’ä½œç”¨' in item or 'è¯ç‰©ç›¸äº’ä½œç”¨' in item:
                    drug_info['data']['interactions'] = content
                elif 'è¯åŠ¨å­¦' in item:
                    drug_info['data']['pharmacokinetics'] = content
        
        # ç±»åˆ«/ä½œç”¨ç‰¹ç‚¹/å…¸å‹ä¸è‰¯ååº”è¡¨
        elif 'ç±»åˆ«' in table.headers and 'ä½œç”¨ç‰¹ç‚¹' in table.headers:
            drug_info['type'] = 'category_details'
            drug_info['data'] = []
            for row in table.rows:
                drug_info['data'].append({
                    'category': row.get('ç±»åˆ«', ''),
                    'characteristics': row.get('ä½œç”¨ç‰¹ç‚¹', ''),
                    'adverse_reactions': row.get('å…¸å‹ä¸è‰¯ååº”', '')
                })
        
        # è€ƒç‚¹/è€ƒæŸ¥å¹´ä»½è¡¨
        elif 'è€ƒç‚¹' in table.headers and 'è€ƒæŸ¥å¹´ä»½' in table.headers:
            drug_info['type'] = 'exam_points'
            drug_info['data'] = []
            for row in table.rows:
                drug_info['data'].append({
                    'point': row.get('è€ƒç‚¹', ''),
                    'years': row.get('è€ƒæŸ¥å¹´ä»½', '')
                })
        
        return drug_info

    def parse_all_pages(self):
        """è§£ææ‰€æœ‰é¡µé¢"""
        print("\nå¼€å§‹è§£ææ‰€æœ‰é¡µé¢...")
        
        current_chapter = ""
        current_section = ""
        current_exam_point = ""
        current_content = []
        current_drug = None
        current_content_type = None
        
        for page in self.pages:
            page_data = self.extract_from_page(page)
            page_idx = page_data['page_idx']
            
            # å¤„ç†è¡¨æ ¼æ•°æ®
            for table in page_data['tables']:
                drug_info = self.extract_drug_info_from_table(table)
                if drug_info:
                    self._process_table_drug_info(drug_info, current_chapter, current_section)
            
            # å¤„ç†æ–‡æœ¬å†…å®¹
            for text_item in page_data['texts']:
                content = text_item['content']
                text_type = text_item['type']
                
                # è·³è¿‡é¡µçœ‰é¡µè„š
                if 'ç™¾ä¸‡å¤§å­¦ç”Ÿ' in content or 'å¾®ä¿¡' in content:
                    continue
                if content.isdigit() and len(content) <= 3:
                    continue
                
                # è¯†åˆ«ç« èŠ‚
                chapter_match = self.CHAPTER_PATTERN.match(content)
                if chapter_match:
                    cn_num = chapter_match.group(1)
                    title = chapter_match.group(2).strip()
                    current_chapter = f"ç¬¬{cn_num}ç«  {title}"
                    current_section = ""
                    print(f"  å‘ç°ç« èŠ‚: {current_chapter}")
                    continue
                
                section_match = self.SECTION_PATTERN.match(content)
                if section_match:
                    cn_num = section_match.group(1)
                    title = section_match.group(2).strip()
                    current_section = f"ç¬¬{cn_num}èŠ‚ {title}"
                    print(f"    å‘ç°å°èŠ‚: {current_section}")
                    continue
                
                # è¯†åˆ«è€ƒç‚¹
                exam_point_match = self.EXAM_POINT_PATTERN.match(content)
                if exam_point_match:
                    # ä¿å­˜ä¹‹å‰çš„è€ƒç‚¹
                    if current_exam_point and current_content:
                        self._save_exam_point(current_chapter, current_section,
                                             current_exam_point, current_content)
                    
                    point_num = exam_point_match.group(1)
                    point_name = exam_point_match.group(2).strip()
                    current_exam_point = f"è€ƒç‚¹{point_num} {point_name}"
                    current_content = []
                    print(f"      å‘ç°è€ƒç‚¹: {current_exam_point}")
                    continue
                
                # è¯†åˆ«å†…å®¹ç±»å‹
                new_content_type = self.identify_content_type(content)
                if new_content_type:
                    current_content_type = new_content_type
                
                # è¯†åˆ«è¯ç‰©åç§°
                drug_name = self.identify_drug_name(content)
                if drug_name:
                    if drug_name not in self.drugs:
                        self.drugs[drug_name] = DrugInfo(
                            name=drug_name,
                            category=current_section or current_chapter
                        )
                    current_drug = drug_name
                
                # æ”¶é›†è¯ç‰©ç›¸å…³å†…å®¹
                if current_drug and current_drug in self.drugs:
                    self._add_content_to_drug(
                        self.drugs[current_drug],
                        content,
                        current_content_type
                    )
                
                # æ”¶é›†è€ƒç‚¹å†…å®¹
                if current_exam_point:
                    current_content.append(content)
        
        # ä¿å­˜æœ€åä¸€ä¸ªè€ƒç‚¹
        if current_exam_point and current_content:
            self._save_exam_point(current_chapter, current_section,
                                 current_exam_point, current_content)
        
        print(f"\nè§£æå®Œæˆ:")
        print(f"  - è¯ç‰©æ•°é‡: {len(self.drugs)}")
        print(f"  - è€ƒç‚¹æ•°é‡: {len(self.exam_points)}")
        print(f"  - è¡¨æ ¼æ•°é‡: {len(self.tables)}")
        print(f"  - å›¾ç‰‡å¼•ç”¨: {len(self.image_references)}")
    
    def _process_table_drug_info(self, drug_info: Dict, chapter: str, section: str):
        """å¤„ç†ä»è¡¨æ ¼æå–çš„è¯ç‰©ä¿¡æ¯"""
        info_type = drug_info.get('type', '')
        data = drug_info.get('data', {})
        
        if info_type == 'classification':
            # è¯ç‰©åˆ†ç±»è¡¨
            for item in data:
                category = item.get('category', '')
                drugs_str = item.get('drugs', '')
                # æå–è¯ç‰©åç§°
                for drug_name in self.KNOWN_DRUGS:
                    if drug_name in drugs_str:
                        if drug_name not in self.drugs:
                            self.drugs[drug_name] = DrugInfo(
                                name=drug_name,
                                category=section or chapter,
                                subcategory=category
                            )
                        else:
                            self.drugs[drug_name].subcategory = category
        
        elif info_type == 'details':
            # è¯¦ç»†ä¿¡æ¯è¡¨ - è§£æå¹¶å…³è”åˆ°å…·ä½“è¯ç‰©
            for key, content in data.items():
                if not content:
                    continue
                self._parse_and_assign_drug_content(key, content, section or chapter)
        
        elif info_type == 'category_details':
            # ç±»åˆ«è¯¦æƒ…è¡¨
            for item in data:
                category = item.get('category', '')
                characteristics = item.get('characteristics', '')
                adverse = item.get('adverse_reactions', '')
                
                # æå–è¯ç‰©åç§°å¹¶å…³è”ä¿¡æ¯
                for drug_name in self.KNOWN_DRUGS:
                    if drug_name in category or drug_name in characteristics:
                        if drug_name not in self.drugs:
                            self.drugs[drug_name] = DrugInfo(
                                name=drug_name,
                                category=section or chapter
                            )
                        
                        drug = self.drugs[drug_name]
                        if characteristics:
                            drug.characteristics.special_features.append(characteristics)
                        if adverse:
                            drug.adverse_reactions.typical.append(adverse)
    
    def _parse_and_assign_drug_content(self, content_type: str, content: str, section: str):
        """è§£æè¡¨æ ¼å†…å®¹å¹¶åˆ†é…åˆ°å…·ä½“è¯ç‰©"""
        # æŒ‰è¯ç‰©åç§°åˆ†å‰²å†…å®¹
        # å¸¸è§æ ¼å¼: (1)è¯ç‰©åç§°: å†…å®¹ (2)è¯ç‰©åç§°: å†…å®¹
        # æˆ–è€…: 1)è¯ç‰©åç§°: å†…å®¹ 2)è¯ç‰©åç§°: å†…å®¹
        
        # é¦–å…ˆå¤„ç†æ•´ä½“å†…å®¹ï¼ˆå¦‚NSAIDsç±»çš„å…±æ€§ä¿¡æ¯ï¼‰
        if content_type == 'mechanism':
            # ä½œç”¨æœºåˆ¶é€šå¸¸æ˜¯ç±»åˆ«å…±æ€§ï¼Œåˆ†é…ç»™è¯¥ç±»åˆ«ä¸‹æ‰€æœ‰è¯ç‰©
            for drug_name in self.KNOWN_DRUGS:
                if drug_name in content:
                    if drug_name not in self.drugs:
                        self.drugs[drug_name] = DrugInfo(name=drug_name, category=section)
                    self.drugs[drug_name].characteristics.mechanism.append(content)
        
        elif content_type == 'characteristics':
            # ä½œç”¨ç‰¹ç‚¹ - è§£æå…·ä½“è¯ç‰©ä¿¡æ¯
            self._parse_numbered_drug_content(content, 'characteristics', section)
        
        elif content_type == 'adverse_reactions':
            # ä¸è‰¯ååº” - è§£æå…·ä½“è¯ç‰©ä¿¡æ¯
            self._parse_numbered_drug_content(content, 'adverse_reactions', section)
        
        elif content_type == 'interactions':
            # è¯ç‰©ç›¸äº’ä½œç”¨
            self._parse_numbered_drug_content(content, 'interactions', section)
        
        elif content_type == 'contraindications':
            # ç¦å¿Œè¯
            self._parse_numbered_drug_content(content, 'contraindications', section)
    
    def _parse_numbered_drug_content(self, content: str, info_type: str, section: str):
        """è§£æå¸¦ç¼–å·çš„è¯ç‰©å†…å®¹"""
        # å°è¯•æŒ‰ç¼–å·åˆ†å‰²: (1)xxx (2)xxx æˆ– 1)xxx 2)xxx
        import re
        
        # åˆ†å‰²æ¨¡å¼
        parts = re.split(r'\(\d+\)|\d+\)', content)
        
        for part in parts:
            part = part.strip()
            if not part:
                continue
            
            # æŸ¥æ‰¾è¯¥éƒ¨åˆ†æåˆ°çš„è¯ç‰©
            mentioned_drugs = []
            for drug_name in self.KNOWN_DRUGS:
                if drug_name in part:
                    mentioned_drugs.append(drug_name)
            
            # å¦‚æœæ‰¾åˆ°è¯ç‰©ï¼Œå°†å†…å®¹å…³è”åˆ°è¿™äº›è¯ç‰©
            for drug_name in mentioned_drugs:
                if drug_name not in self.drugs:
                    self.drugs[drug_name] = DrugInfo(name=drug_name, category=section)
                
                drug = self.drugs[drug_name]
                
                if info_type == 'characteristics':
                    if part not in drug.characteristics.special_features:
                        drug.characteristics.special_features.append(part)
                elif info_type == 'adverse_reactions':
                    severity = self.classify_adverse_severity(part)
                    if severity == 'severe':
                        if part not in drug.adverse_reactions.severe:
                            drug.adverse_reactions.severe.append(part)
                    elif severity == 'moderate':
                        if part not in drug.adverse_reactions.moderate:
                            drug.adverse_reactions.moderate.append(part)
                    else:
                        if part not in drug.adverse_reactions.mild:
                            drug.adverse_reactions.mild.append(part)
                    # åŒæ—¶æ·»åŠ åˆ°å…¸å‹ä¸è‰¯ååº”
                    if part not in drug.adverse_reactions.typical:
                        drug.adverse_reactions.typical.append(part)
                elif info_type == 'interactions':
                    if part not in drug.interactions.general:
                        drug.interactions.general.append(part)
                elif info_type == 'contraindications':
                    if part not in drug.contraindications:
                        drug.contraindications.append(part)
    
    def _add_content_to_drug(self, drug: DrugInfo, content: str, content_type: Optional[str]):
        """å°†å†…å®¹æ·»åŠ åˆ°è¯ç‰©ä¿¡æ¯ä¸­"""
        if not content or len(content) < 5:
            return
        
        if content_type == 'mechanism':
            drug.characteristics.mechanism.append(content)
        elif content_type == 'characteristics':
            drug.characteristics.special_features.append(content)
        elif content_type == 'pharmacokinetics':
            # è§£æè¯åŠ¨å­¦å‚æ•°
            if 'åŠè¡°æœŸ' in content:
                drug.characteristics.pharmacokinetics['åŠè¡°æœŸ'] = content
            elif 'ä»£è°¢' in content:
                drug.characteristics.pharmacokinetics['ä»£è°¢'] = content
            elif 'å¸æ”¶' in content:
                drug.characteristics.pharmacokinetics['å¸æ”¶'] = content
            else:
                drug.characteristics.pharmacokinetics['å…¶ä»–'] = content
        elif content_type == 'adverse_reactions':
            severity = self.classify_adverse_severity(content)
            if severity == 'severe':
                drug.adverse_reactions.severe.append(content)
            elif severity == 'moderate':
                drug.adverse_reactions.moderate.append(content)
            else:
                drug.adverse_reactions.mild.append(content)
        elif content_type == 'contraindications':
            drug.contraindications.append(content)
        elif content_type == 'interactions':
            drug.interactions.general.append(content)
        elif content_type == 'indications':
            drug.clinical_use.append(content)
        elif content_type == 'precautions':
            drug.precautions.append(content)
    
    def _save_exam_point(self, chapter: str, section: str, point_name: str, content: List[str]):
        """ä¿å­˜è€ƒç‚¹ä¿¡æ¯"""
        # æå–è€ƒè¯•å¹´ä»½
        exam_years = []
        year_pattern = re.compile(r'20[12]\d')
        for text in content:
            years = year_pattern.findall(text)
            exam_years.extend(years)
        exam_years = list(set(exam_years))
        
        # æå–ç›¸å…³è¯ç‰©
        related_drugs = []
        for text in content:
            for drug in self.KNOWN_DRUGS:
                if drug in text and drug not in related_drugs:
                    related_drugs.append(drug)
        
        exam_point = ExamPoint(
            name=point_name,
            chapter=chapter,
            section=section,
            exam_years=sorted(exam_years),
            content='\n'.join(content),
            related_drugs=related_drugs
        )
        self.exam_points.append(exam_point)
    
    def extract(self):
        """æ‰§è¡Œæå–"""
        self.load_data()
        self.parse_all_pages()
    
    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            "è¯ç‰©æ€»æ•°": len(self.drugs),
            "è€ƒç‚¹æ€»æ•°": len(self.exam_points),
            "è¡¨æ ¼æ€»æ•°": len(self.tables),
            "å›¾ç‰‡å¼•ç”¨æ•°": len(self.image_references),
            "è¯ç‰©åˆ—è¡¨": list(self.drugs.keys())
        }
        
        # è¯ç‰©ä¿¡æ¯
        drugs_data = {}
        for name, drug in self.drugs.items():
            drugs_data[name] = {
                "åç§°": drug.name,
                "åˆ†ç±»": drug.category,
                "äºšç±»": drug.subcategory,
                "ä½œç”¨ç‰¹ç‚¹": {
                    "ä½œç”¨æœºåˆ¶": drug.characteristics.mechanism,
                    "é€‰æ‹©æ€§": drug.characteristics.selectivity,
                    "é€‚åº”è¯": drug.characteristics.indications,
                    "è¯åŠ¨å­¦": drug.characteristics.pharmacokinetics,
                    "ç‰¹æ®Šç‰¹ç‚¹": drug.characteristics.special_features
                },
                "ä¸è‰¯ååº”": {
                    "ä¸¥é‡": drug.adverse_reactions.severe,
                    "ä¸­åº¦": drug.adverse_reactions.moderate,
                    "è½»åº¦": drug.adverse_reactions.mild,
                    "å¸¸è§": drug.adverse_reactions.common,
                    "å…¸å‹": drug.adverse_reactions.typical
                },
                "è¯ç‰©ç›¸äº’ä½œç”¨": {
                    "ååŒ": drug.interactions.synergistic,
                    "æ‹®æŠ—": drug.interactions.antagonistic,
                    "ç¦å¿Œåˆç”¨": drug.interactions.contraindicated,
                    "æ…é‡åˆç”¨": drug.interactions.caution,
                    "ä¸€èˆ¬": drug.interactions.general
                },
                "ç¦å¿Œè¯": drug.contraindications,
                "æ³¨æ„äº‹é¡¹": drug.precautions,
                "ç”¨æ³•ç”¨é‡": drug.dosage,
                "ä¸´åºŠåº”ç”¨": drug.clinical_use,
                "ç‰¹æ®Šäººç¾¤ç”¨è¯": drug.special_populations,
                "è€ƒç‚¹æ ‡è®°": drug.exam_points,
                "ç›¸å…³å›¾ç‰‡": drug.related_images
            }
        
        # è€ƒç‚¹åˆ—è¡¨
        exam_points_data = []
        for point in self.exam_points:
            exam_points_data.append({
                "åç§°": point.name,
                "ç« èŠ‚": point.chapter,
                "å°èŠ‚": point.section,
                "è€ƒè¯•å¹´ä»½": point.exam_years,
                "ç›¸å…³è¯ç‰©": point.related_drugs,
                "å†…å®¹": point.content
            })
        
        # è¡¨æ ¼æ•°æ®
        tables_data = []
        for table in self.tables:
            tables_data.append({
                "æ ‡é¢˜": table.title,
                "è¡¨å¤´": table.headers,
                "æ•°æ®è¡Œ": table.rows,
                "æ¥æºå›¾ç‰‡": table.source_image,
                "é¡µç ": table.page_idx
            })
        
        # å›¾ç‰‡å¼•ç”¨
        images_data = {}
        for img_path, info in self.image_references.items():
            images_data[img_path] = info
        
        return {
            "ç»Ÿè®¡ä¿¡æ¯": stats,
            "è¯ç‰©ä¿¡æ¯": drugs_data,
            "è€ƒç‚¹åˆ—è¡¨": exam_points_data,
            "è¡¨æ ¼æ•°æ®": tables_data,
            "å›¾ç‰‡å¼•ç”¨": images_data
        }
    
    def save(self, output_path: str):
        """ä¿å­˜ç»“æœ"""
        result = self.to_dict()
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"\nç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    def print_summary(self):
        """æ‰“å°æ‘˜è¦"""
        print("\n" + "=" * 70)
        print("ğŸ“š è¥¿è¯è¯äºŒçŸ¥è¯†ç‚¹æå–ç»“æœæ‘˜è¦")
        print("=" * 70)
        
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  - è¯ç‰©æ•°é‡: {len(self.drugs)}")
        print(f"  - è€ƒç‚¹æ•°é‡: {len(self.exam_points)}")
        print(f"  - è¡¨æ ¼æ•°é‡: {len(self.tables)}")
        print(f"  - å›¾ç‰‡å¼•ç”¨: {len(self.image_references)}")
        
        print(f"\nğŸ’Š è¯ç‰©åˆ—è¡¨ï¼ˆå‰30ä¸ªï¼‰:")
        for i, (name, drug) in enumerate(list(self.drugs.items())[:30]):
            features_count = len(drug.characteristics.special_features)
            adverse_count = (len(drug.adverse_reactions.severe) + 
                           len(drug.adverse_reactions.moderate) + 
                           len(drug.adverse_reactions.mild) +
                           len(drug.adverse_reactions.typical))
            interactions_count = len(drug.interactions.general)
            
            print(f"  {i+1}. {name}")
            print(f"      åˆ†ç±»: {drug.category}")
            if drug.subcategory:
                print(f"      äºšç±»: {drug.subcategory}")
            print(f"      ä½œç”¨ç‰¹ç‚¹: {features_count}æ¡, ä¸è‰¯ååº”: {adverse_count}æ¡, ç›¸äº’ä½œç”¨: {interactions_count}æ¡")
        
        print(f"\nğŸ“‹ è¡¨æ ¼æ•°æ®é¢„è§ˆï¼ˆå‰10ä¸ªï¼‰:")
        for i, table in enumerate(self.tables[:10]):
            print(f"  {i+1}. è¡¨å¤´: {table.headers}")
            print(f"      æ•°æ®è¡Œæ•°: {len(table.rows)}")
            if table.source_image:
                print(f"      æ¥æºå›¾ç‰‡: {table.source_image}")
        
        print(f"\nğŸ–¼ï¸ å›¾ç‰‡å¼•ç”¨ï¼ˆå‰10ä¸ªï¼‰:")
        for i, (img_path, info) in enumerate(list(self.image_references.items())[:10]):
            print(f"  {i+1}. {img_path}")
            print(f"      é¡µç : {info.get('page_idx', 'N/A')}")


def main():
    """ä¸»å‡½æ•°"""
    # è¾“å…¥è¾“å‡ºè·¯å¾„
    input_path = "shuju/layout.json"
    images_dir = "shuju/images"
    output_path = "shuju/è¥¿è¯è¯äºŒ_çŸ¥è¯†ç‚¹_å®Œæ•´ç‰ˆ.json"
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(input_path):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ {input_path}")
        return
    
    # åˆ›å»ºæå–å™¨å¹¶æ‰§è¡Œ
    extractor = EnhancedKnowledgeExtractor(input_path, images_dir)
    extractor.extract()
    extractor.print_summary()
    extractor.save(output_path)
    
    print("\nâœ… æå–å®Œæˆ!")
    print(f"  - è¾“å‡ºæ–‡ä»¶: {output_path}")
    print(f"  - å›¾ç‰‡ç›®å½•: {images_dir}")
    print("\nğŸ’¡ æç¤º: å›¾ç‰‡ä¸­çš„è¡¨æ ¼å†…å®¹å·²é€šè¿‡HTMLè§£ææå–")
    print("   å¦‚éœ€è¿›ä¸€æ­¥æå–å›¾ç‰‡ä¸­çš„æ–‡å­—ï¼Œå¯ä½¿ç”¨OCRå·¥å…·å¤„ç† images ç›®å½•ä¸­çš„å›¾ç‰‡")


if __name__ == "__main__":
    main()
