#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CSVè½¬SQLå¯¼å…¥å·¥å…·
===============
å°†CSVæ ¼å¼çš„é¢˜åº“æ•°æ®è½¬æ¢ä¸ºSupabase SQLå¯¼å…¥æ–‡ä»¶

ä½¿ç”¨æ–¹æ³•ï¼š
  python csv_to_sql.py é¢˜åº“.csv
  python csv_to_sql.py é¢˜åº“.csv --output custom.sql
"""

import csv
import json
import argparse
from datetime import datetime
from pathlib import Path


def csv_to_sql(csv_file: str, output_file: str = None, year: int = 2024):
    """å°†CSVè½¬æ¢ä¸ºSQL"""
    
    print(f"ğŸš€ CSVè½¬SQLå·¥å…·")
    print(f"{'='*70}\n")
    
    # è¯»å–CSV
    print(f"ğŸ“– è¯»å–æ–‡ä»¶ï¼š{csv_file}")
    questions = []
    
    with open(csv_file, 'r', encoding='utf-8-sig') as f:  # utf-8-sigå¤„ç†BOM
        reader = csv.DictReader(f)
        for row in reader:
            if not row.get('é¢˜å·'):  # è·³è¿‡ç©ºè¡Œ
                continue
            
            q = {
                'number': int(row['é¢˜å·']),
                'type': row['é¢˜å‹'],
                'content': row['é¢˜ç›®å†…å®¹'],
                'options': {
                    'A': row['é€‰é¡¹A'],
                    'B': row['é€‰é¡¹B'],
                    'C': row['é€‰é¡¹C'],
                    'D': row['é€‰é¡¹D'],
                    'E': row['é€‰é¡¹E']
                },
                'answer': row['ç­”æ¡ˆ'],
                'explanation': row['è§£æ']
            }
            questions.append(q)
    
    print(f"âœ… æˆåŠŸè¯»å– {len(questions)} é“é¢˜\n")
    
    # ç”ŸæˆSQL
    print("ğŸ“ ç”ŸæˆSQLæ–‡ä»¶...")
    
    if not output_file:
        output_file = f'import-{year}-questions-complete.sql'
    
    sql_parts = []
    
    # æ–‡ä»¶å¤´
    header = f"""-- ================================================================
-- åŒ»è€ƒé¢˜åº“å¯¼å…¥SQL - ä»CSVç”Ÿæˆ
-- ================================================================
-- å¹´ä»½ï¼š{year}
-- é¢˜ç›®æ€»æ•°ï¼š{len(questions)} é“
-- ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
-- æ•°æ®æ¥æºï¼š{csv_file}
-- ================================================================

-- æ¸…ç†ç°æœ‰æ•°æ®
DELETE FROM questions 
WHERE exam_type = 'æ‰§ä¸šè¯å¸ˆ' 
  AND subject = 'ä¸­è¯å­¦ç»¼åˆçŸ¥è¯†ä¸æŠ€èƒ½' 
  AND source_year = {year};

-- æ‰¹é‡æ’å…¥
"""
    sql_parts.append(header)
    
    # é¢˜å‹æ˜ å°„
    type_map = {
        'single': 'æœ€ä½³é€‰æ‹©é¢˜',
        'match': 'é…ä¼é€‰æ‹©é¢˜',
        'comprehensive': 'ç»¼åˆåˆ†æé¢˜',
        'multiple': 'å¤šé¡¹é€‰æ‹©é¢˜'
    }
    
    # ç”ŸæˆINSERTè¯­å¥
    for q in questions:
        num = q['number']
        qtype = q['type']
        type_name = type_map.get(qtype, qtype)
        
        content = q['content'].replace("'", "''").replace("\\", "\\\\")
        explanation = q['explanation'].replace("'", "''").replace("\\", "\\\\")
        
        # å¤„ç†é€‰é¡¹ - åªåŒ…å«éç©ºé€‰é¡¹
        options_list = []
        for key in ['A', 'B', 'C', 'D', 'E']:
            value = q['options'].get(key, '')
            if value:
                options_list.append({'key': key, 'value': str(value)})
        
        options_json = json.dumps(options_list, ensure_ascii=False).replace("'", "''")
        
        sql = f"""
-- ç¬¬{num}é¢˜ - {type_name}
INSERT INTO questions (
  exam_type, subject, chapter, question_type, content, options,
  correct_answer, explanation, difficulty, knowledge_points,
  source_type, source_year, is_published
) VALUES (
  'æ‰§ä¸šè¯å¸ˆ',
  'ä¸­è¯å­¦ç»¼åˆçŸ¥è¯†ä¸æŠ€èƒ½',
  'ç»¼åˆçŸ¥è¯†',
  '{qtype}',
  '{content}',
  '{options_json}'::json,
  '{q["answer"]}',
  '{explanation}',
  2,
  ARRAY['ç»¼åˆçŸ¥è¯†'],
  'å†å¹´çœŸé¢˜',
  {year},
  true
);
"""
        sql_parts.append(sql)
    
    # éªŒè¯æŸ¥è¯¢
    footer = f"""
-- ================================================================
-- éªŒè¯å¯¼å…¥ç»“æœ
-- ================================================================
SELECT 
  question_type as "é¢˜å‹",
  COUNT(*) as "æ•°é‡"
FROM questions 
WHERE source_year = {year}
GROUP BY question_type;

SELECT COUNT(*) as "æ€»æ•°" FROM questions WHERE source_year = {year};
"""
    sql_parts.append(footer)
    
    # ä¿å­˜æ–‡ä»¶
    sql_content = '\n'.join(sql_parts)
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(sql_content)
    
    print(f"âœ… SQLæ–‡ä»¶ç”ŸæˆæˆåŠŸï¼š{output_file}")
    print(f"   æ–‡ä»¶å¤§å°ï¼š{len(sql_content) / 1024:.1f} KB")
    print(f"   é¢˜ç›®æ•°é‡ï¼š{len(questions)} é“\n")
    
    # ç»Ÿè®¡ä¿¡æ¯
    type_count = {}
    for q in questions:
        qtype = q['type']
        type_count[qtype] = type_count.get(qtype, 0) + 1
    
    print("ğŸ“Š é¢˜å‹åˆ†å¸ƒï¼š")
    for qtype, count in sorted(type_count.items()):
        type_name = type_map.get(qtype, qtype)
        print(f"   - {type_name}: {count} é“")
    
    print(f"\n{'='*70}")
    print("ğŸ’¡ ä¸‹ä¸€æ­¥ï¼š")
    print(f"   1. æ‰“å¼€ Supabase SQL ç¼–è¾‘å™¨")
    print(f"   2. å¤åˆ¶ç²˜è´´ {output_file} çš„å†…å®¹")
    print(f"   3. ç‚¹å‡»è¿è¡Œ")
    print(f"{'='*70}\n")
    
    return True


def main():
    parser = argparse.ArgumentParser(description='CSVè½¬SQLå·¥å…·')
    parser.add_argument('input', help='è¾“å…¥CSVæ–‡ä»¶')
    parser.add_argument('--output', '-o', help='è¾“å‡ºSQLæ–‡ä»¶')
    parser.add_argument('--year', '-y', type=int, default=2024, help='å¹´ä»½')
    
    args = parser.parse_args()
    
    if not Path(args.input).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼š{args.input}")
        return
    
    csv_to_sql(args.input, args.output, args.year)


if __name__ == '__main__':
    main()
